{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Decision Tree\n",
    "\n",
    "---\n",
    "**Written by Hendi Lie (h2.lie@qut.edu.au) and Richi Nayak (r.nayak@qut.edu.au). All rights reserved.**\n",
    "\n",
    "Welcome to the third practical exercise for IFN645. Each exercise sheet contains a number of theoretical and programming exercises, designed to strengthen both conceptual and practical understanding of data mining processes in this unit.\n",
    "\n",
    "To answer conceptual questions, write the answer to each question on a paper/note with your reasoning. For programming exercises, open your iPython console/Jupyter notebook and use Python commands/libraries introduced in each practical to answer the questions. In many cases, you will need to write code to support your conceptual answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prequisite\n",
    "\n",
    "Perform the following steps before trying the exercises:\n",
    "1. Import pandas as \"pd\" and load the house price dataset into \"df\".\n",
    "2. Print dataset information to refresh your memory.\n",
    "3. Run `preprocess_data` function on the dataframe to perform preprocessing steps discussed last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datasets/melbourne_house_price.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24197 entries, 0 to 24196\n",
      "Data columns (total 22 columns):\n",
      "Suburb                24197 non-null object\n",
      "Address               24197 non-null object\n",
      "Rooms                 24197 non-null int64\n",
      "Type                  24197 non-null object\n",
      "Price                 24197 non-null float64\n",
      "Method                24197 non-null object\n",
      "SellerG               24197 non-null object\n",
      "Date                  24197 non-null object\n",
      "Distance              24196 non-null float64\n",
      "Postcode              24196 non-null float64\n",
      "Bedroom2              18673 non-null float64\n",
      "Bathroom              18669 non-null float64\n",
      "Car                   18394 non-null float64\n",
      "Landsize              15946 non-null float64\n",
      "BuildingArea          9609 non-null float64\n",
      "YearBuilt             10961 non-null float64\n",
      "CouncilArea           24194 non-null object\n",
      "Lattitude             18843 non-null float64\n",
      "Longtitude            18843 non-null float64\n",
      "Regionname            24194 non-null object\n",
      "Propertycount         24194 non-null float64\n",
      "Price_above_median    24197 non-null int64\n",
      "dtypes: float64(12), int64(2), object(8)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Q1.4 and Q6.2\n",
    "    df = df.drop(['Address', 'Landsize', 'BuildingArea', 'YearBuilt', 'Price', 'Bedroom2', 'SellerG'], axis=1)\n",
    "    \n",
    "    # Q1.1\n",
    "    cols_miss_drop =['Postcode', 'CouncilArea', 'Regionname', 'Propertycount']\n",
    "    mask = pd.isnull(df['Distance'])\n",
    "\n",
    "    for col in cols_miss_drop:\n",
    "        mask = mask | pd.isnull(df[col])\n",
    "\n",
    "    df = df[~mask]\n",
    "    \n",
    "    # Q1.2\n",
    "    df['Bathroom'].fillna(df['Bathroom'].mean(), inplace=True)\n",
    "    df['Car'].fillna(df['Car'].mean(), inplace=True)\n",
    "    \n",
    "    df['Latitude_nan'] = pd.isnull(df['Lattitude'])\n",
    "    df['Longtitude_nan'] = pd.isnull(df['Longtitude'])\n",
    "    df['Lattitude'].fillna(0, inplace=True)\n",
    "    df['Longtitude'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Q6.1. Change date into weeks and months\n",
    "    df['Sales_week'] = pd.to_datetime(df['Date']).dt.week\n",
    "    df['Sales_month'] = pd.to_datetime(df['Date']).dt.month\n",
    "    df = df.drop(['Date'], axis=1)  # drop the date, not required anymore\n",
    "    \n",
    "    # Q4\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_prep = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24194 entries, 0 to 24196\n",
      "Columns: 402 entries, Rooms to Regionname_Western Victoria\n",
      "dtypes: bool(2), float64(7), int64(4), uint8(389)\n",
      "memory usage: 11.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_prep.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Partitioning\n",
    "\n",
    "Perform following operations and answer the following questions:\n",
    "1. Describe training, validation and test dataset. What is the purpose for each of these split?\n",
    "2. What is k-fold cross validation? What is the advantage and disadvantage of k-fold CV compared to normal training/test/validation method?\n",
    "3. What does it mean by *stratification*?\n",
    "4. What does random state do?\n",
    "5. Set random state to 0. Split the dataframe into X and Y, then split respective data into training and test set of 70/30 proportion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Question 1, 2, 3 and 4 are throughly explained in the practical and lecture notes.\n",
    "\n",
    "Question 5 is as follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rs = 0\n",
    "X = df_prep.drop(['Price_above_median'], axis=1)\n",
    "y = df_prep['Price_above_median']\n",
    "\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.3, stratify=y, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree\n",
    "\n",
    "Perform the following operations and answer the question.\n",
    "1. Import and build a decision tree classifier. Set the random state to 0 to ensure your result is similar with the answers. Fit it against the training data.\n",
    "2. What is the performance of the model against training data? How about against the test data? Do you see any indication of overfitting here?\n",
    "3. What are the top 5 most important features in this model?\n",
    "4. Find the best hyperparameters using GridSearchCV. What is the optimal parameter set? Use the following parameters as initial guidance **criterion** of `gini` or `entropy`, **max depth** of 2-7 and **min_samples_leaf** from 20-60, increment of 10.\n",
    "    \n",
    "5. Visualise the structure of your decision tree. Can you identify characteristics of expensive houses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "Code to answer all questions are as follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from dm_tools import visualize_decision_tree, analyse_feature_importance  # use the functions we build in the practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=rs)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981694715087098\n",
      "0.8425402948064472\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major difference between performance on training data vs test data. Strong indication of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type_u : 0.1663717197004314\n",
      "Distance : 0.14105464031286377\n",
      "Regionname_Southern Metropolitan : 0.13320735698073669\n",
      "Longtitude : 0.0735364961075368\n",
      "Regionname_Eastern Metropolitan : 0.07287281292272205\n",
      "Rooms : 0.05997213997847961\n",
      "Lattitude : 0.05692904637420696\n",
      "Sales_week : 0.0454671733784824\n",
      "Postcode : 0.02886272712831667\n",
      "Type_h : 0.02641844227105693\n",
      "Sales_month : 0.02341347233009052\n",
      "Car : 0.022237535375885464\n",
      "Bathroom : 0.02199774346522733\n",
      "CouncilArea_Kingston City Council : 0.015772356922391702\n",
      "Propertycount : 0.01518330039036208\n",
      "CouncilArea_Monash City Council : 0.012291156725175655\n",
      "Method_S : 0.009123962832994232\n",
      "Method_PI : 0.007633009722691979\n",
      "Type_t : 0.00604574606420386\n",
      "Method_VB : 0.004303988332194074\n"
     ]
    }
   ],
   "source": [
    "analyse_feature_importance(model, X.columns, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "House type, distance from CBD, regions, location and rooms are the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8478299379982285\n",
      "Test accuracy: 0.8422647747623639\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.87      0.85      3634\n",
      "          1       0.86      0.82      0.84      3625\n",
      "\n",
      "avg / total       0.84      0.84      0.84      7259\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid search CV\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(2, 7),\n",
    "          'min_samples_leaf': range(200, 600, 100)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "# test the best model\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model generalises better on both training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize_decision_tree(cv.best_estimator_, X.columns, \"optimal_tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DT visualisation](optimal_tree.png \"DT visualisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite hard to see on the notebook, but if you open the file and zoom in into the right most branch in the picture, one characteristics set of the more expensive houses are\n",
    "1. (Type_u <= 0.5 == False) = Unit houses.\n",
    "2. (Rooms <= 2.5 == False) = With more than 2.5 rooms (3 rooms and above)\n",
    "3. (Regionname_Southern_Metropolitan) <= 0.5 == False) = Located in Melbourne's Southern Metropolitan area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "\n",
    "When you are finished with all exercise questions, the sample answers are available in the following Github repository. Remember, please try the exercises first before viewing the answers.\n",
    "\n",
    "https://github.com/liehendi11/IFN645_answers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
